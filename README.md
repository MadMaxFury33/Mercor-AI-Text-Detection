# üß† Mercor AI Text Detection  
### Detecting AI-Generated Writing Using XGBoost, Optuna, RoBERTa-Base & RoBERTa-Large


<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10-blue?style=for-the-badge">
  <img src="https://img.shields.io/badge/HuggingFace-Transformers-orange?style=for-the-badge">
  <img src="https://img.shields.io/badge/XGBoost-1.7+-lightgrey?style=for-the-badge">
  <img src="https://img.shields.io/badge/Optuna-AutoML-success?style=for-the-badge">
  <img src="https://img.shields.io/badge/Status-Active-brightgreen?style=for-the-badge">
</p>

---

This repository contains my complete solution for the **Mercor AI Text Detection Competition**, where the objective is to classify whether a writing sample is **human-written (0)** or **AI-generated (1)**.

I built, compared, and optimized several models:

- ‚úîÔ∏è **XGBoost baseline**  
- ‚úîÔ∏è **Optuna hyperparameter-tuned XGBoost**  
- ‚úîÔ∏è **RoBERTa-Base fine-tuned**  
- ‚úîÔ∏è **RoBERTa-Large fine-tuned (best model)**  

Transformers significantly outperformed classical ML models.

---

# üéØ Problem Overview

The challenge is to detect **cheating** in writing assessments by distinguishing human vs AI-generated text.

| Label | Meaning |
|-------|---------|
| **0** | Human-written |
| **1** | AI-generated |

---

# üîß Models Implemented

---

## 1Ô∏è‚É£ XGBoost Baseline

A fast, interpretable baseline using engineered features:

- Text length  
- Unique word ratio  
- Stopword density  
- Punctuation ratios  
- Character-level patterns  
- TF-IDF vectors  

### **Performance**

Validation Accuracy: ~0.66
Validation F1 Score: ~0.77


---

## 2Ô∏è‚É£ XGBoost + Optuna (AutoML)

Used Optuna to tune:

- n_estimators (100‚Äì3000)  
- max_depth (3‚Äì10)  
- learning_rate (0.001‚Äì0.1)  
- min_child_weight (1‚Äì10)  
- subsample (0.5‚Äì1.0)  
- colsample_bytree  
- gamma  

### **Best Example Parameters**
```json
{
  "subsample": 1.0,
  "n_estimators": 800,
  "min_child_weight": 1,
  "max_depth": 3,
  "learning_rate": 0.2,
  "gamma": 0,
  "colsample_bytree": 1.0
}
```
Improved Score
Best R¬≤: 0.885

## 3Ô∏è‚É£ RoBERTa-Base Fine-Tuning

Fine-tuned HuggingFace‚Äôs:

### **Setup**
- HuggingFace Trainer API  
- AdamW optimizer  
- Linear LR scheduler  
- CrossEntropyLoss  
- GPU acceleration  

### **Results**
RoBERTa-Base shows significantly better contextual understanding than all classical ML models, capturing semantics, tone, and coherence more effectively.

---

## 4Ô∏è‚É£ RoBERTa-Large Fine-Tuning (Best Model)


### **Why It Wins**
- 355M parameters  
- Superior contextual depth  
- Better sensitivity to writing style patterns  
- Stronger coherence and fluency detection  

### **Notes**
- Requires more GPU memory  
- Achieved **best validation accuracy & F1 score**  
- Used for **final leaderboard submissions**

---

## üìä Model Performance Summary

| Model                | Accuracy | F1 Score | Notes                        |
|----------------------|----------|----------|------------------------------|
| **XGBoost**          | ~0.66    | ~0.77    | Good baseline                |
| **Optuna-Tuned XGBoost** | ‚Üë        | ‚Üë        | Stable & optimized           |
| **RoBERTa-Base**     | Higher   | Higher   | Strong Transformer baseline  |
| **RoBERTa-Large**    | **Best** | **Best** | Final model used             |

---

## üõ†Ô∏è Installation

### Install dependencies:
```bash

pip install transformers torch scikit-learn xgboost optuna pandas numpy
```

## ‚ñ∂Ô∏è How to Run
1Ô∏è‚É£ XGBoost + Optuna
- jupyter notebook notebooks/Mercor_AI_Text_Detection.ipynb

2Ô∏è‚É£ RoBERTa-Base
- jupyter notebook notebooks/Robertabase.ipynb

3Ô∏è‚É£ RoBERTa-Large
- jupyter notebook notebooks/Robertalarge.ipynb

## üìÅ Outputs
- File	Description
- submission.csv	XGBoost predictions
- submission_roberta.csv	RoBERTa-base predictions




